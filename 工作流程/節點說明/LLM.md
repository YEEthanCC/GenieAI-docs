# LLM
## 定義
呼叫大語言模型回答問題或處理自然語言。
- **意圖識別**， 在客服對話情境中，對使用者問題進行意圖辨識與分類，導向下游不同的流程。
- **文字生成**，在文章生成情境中，作為內容生成的節點，根據主題、關鍵字產生符合的文字內容。
- **內容分類**，在郵件批次情境中，對郵件的類型進行自動化分類，如諮詢/投訴/垃圾郵件。
- **文字轉換**，在文字翻譯情境中，將使用者提供的文字內容翻譯成指定語言。
- **程式碼生**，在輔助程式設計情境中，根據使用者的要求產生指定的業務程式碼，編寫測試案例。
- **RAG**，在知識庫問答情境中，將檢索到的相關知識和使用者問題重新組織回覆問題。
- **圖片理解**，使用vision 能力的多模態模型，能對影像內的訊息進行理解與問答。

選擇合適的模型，寫提示詞，你可以在Chatflow/Workflow 中建立出強大、可靠的解決方案。
## 如何配置
![LLM節點配置-選擇模型](/工作流程/節點說明/images/LLM節點配置-選擇模型)
**設定步驟：**
1. **選擇模型**，GenieAI 提供了全球主流模型的支持，包括OpenAI 的GPT 系列、Anthropic 的Claude 系列、Google 的Gemini 系列等，選擇一個模型取決於其推理能力、成本、響應速度、上下文窗口等因素，你需要根據場景需求和任務類型選擇合適的模型。
2. **配置模型參數**，模型參數用於控制模型的生成結果，例如溫度、TopP，最大標記、回复格式等，為了方便選擇系統同時提供了3 套預設參數：創意，平衡和精確。
3. **寫提示詞**，LLM 節點提供了一個易用的提示詞編排頁面，選擇聊天模型或補全模型，會顯示不同的提示詞編排結構。
4. **進階設置**，可以開關記憶，設置記憶窗口，使用Jinja-2 模版語言來進行更複雜的提示詞等。

如果你是初次使用GenieAI ，在LLM 節點選擇模型之前，需要先在系統設定—模型供應商內提前完成模型配置。

**寫出提示詞**
在LLM 節點內，你可以自訂模型輸入提示詞。如果選擇聊天模型（Chat model），你可以自訂系統提示詞（SYSTEM）/使用者（USER）/助手（ASSISTANT）三部分內容。
![自訂系統提示詞](/工作流程/節點說明/images/自訂系統提示詞.png)
在提示詞編輯器中，你可以透過輸入「/」或「{」呼出變數插入選單，將特殊變數區塊或上游節點變數插入到提示詞中作為上下文內容。
![呼出變數插入選單](/工作流程/節點說明/images/呼出變數插入選單.png)
## 特殊變數說明
**情境變數**
上下文變數是LLM 節點內定義的特殊變數類型，用於在提示詞內插入外部檢索的文字內容。
![上下文變數](/工作流程/節點說明/images/上下文變數.png)
在常見的知識庫問答應用中，知識庫檢索的下游節點一般為LLM 節點，知識檢索的**輸出變數** ```result```需要配置在LLM 節點中的**上下文變數**內關聯賦值。關聯後在提示詞的適當位置插入**上下文變量**，可以將外部檢索到的知識插入提示詞。

該變數除了可以作為LLM 回复問題時的提示詞上下文作為外部知識引入，由於其數據結構中包含了分段引用信息，同時可以支持應用端的引用與歸屬功能。

若上下文變數關聯賦值的是上游節點的普通變量，例如開始節點的字串類型變量，則上下文的變數同樣可以作為外部知識引入，但引用與歸屬功能將會失效。

## 進階功能
**記憶**：開啟記憶後問題分類器的每次輸入將包含對話中的聊天歷史，以幫助LLM 理解上文，提高對話互動中的問題理解能力。

**記憶視窗**：記憶視窗關閉時，系統會根據模型情境視窗動態過濾聊天歷史的傳遞數量；開啟時使用者可以精確控制聊天歷史的傳遞數量（對數）。

**對話角色名設定**：由於模型在訓練階段的差異，不同模型對於角色名的指令遵循程度不同，如Human/Assistant，Human/AI，人類/助手等等。為適配多模型的提示響應效果，系統提供了對話角色名的設置，修改對話角色名稱將會修改會話歷史的角色前綴。

**Jinja-2 範本**： LLM 的提示字編輯器內支援Jinja-2 範本語言，讓你可以藉助Jinja2 這強大的Python 範本語言，實現輕量級資料轉換和邏輯處理，參考官方文件。