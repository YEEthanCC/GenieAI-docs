# 敏感內容審查
我們在與AI 應用交互的過程中，往往在內容安全性，用戶體驗，法律法規等方面有較為苛刻的要求，此時我們需要“敏感詞審查”功能，來為終端用戶創造一個更好的交互環境。 在提示詞編排頁面，點擊“新增功能”，找到底部的工具箱“內容審核”：
![工具箱內容審核](/建構/應用工具箱/images/工具箱內容審核.png)

## 功能一：呼叫OpenAI Moderation API
OpenAI 和大多數LLM 公司提供的模型，都帶有內容審查功能，確保不會輸出包含有爭議的內容，例如暴力，性和非法行為，並且OpenAI 也開放了這種內容審查能力，具體可以參考platform .openai.com。現在你也可以直接在GenieAI 上呼叫OpenAI Moderation API，你可以審核輸入內容或輸出內容，只要輸入對應的「預設回覆」即可。
![OpenAIModerationAPI](/建構/應用工具箱/images/OpenAIModerationAPI.png)

## 功能二：自訂關鍵字
開發者可以自訂需要審查的敏感詞，例如把「kill」當作關鍵字，在使用者輸入的時候作審核動作，要求預設回覆內容為「The content is violating usage policies.」可以預見的結果是當使用者在終端機輸入包含「kill」的語料片段，就會觸發敏感詞審查工具，傳回預設回應內容。
![關鍵字審查](/建構/應用工具箱/images/關鍵字審查.png)

## 功能三： 敏感詞審查Moderation 擴充
不同的企業內部往往有著不同的敏感字詞審查機制，企業在發展自己的AI 應用如企業內部知識庫ChatBot，需要對員工輸入的查詢內容作敏感字詞審查。為此，開發者可以根據自己企業內部的敏感詞審查機制寫一個API 擴展，具體可參考敏感內容審查，從而在GenieAI 上調用，實現敏感詞審查的高度自訂和隱私保護。
![敏感詞審查Moderation擴充](/建構/應用工具箱/images/敏感詞審查Moderation擴充.png)